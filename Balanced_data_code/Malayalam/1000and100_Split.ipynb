{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5a4b4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zfxs5vGpn8QB",
    "outputId": "011b7a23-406f-4162-c8de-2cd615e2efb0"
   },
   "outputs": [],
   "source": [
    "#!gdown --id 1HV6zeS_pqNrDOfHr3A7UvJKnyzy5u4K1\n",
    "#!gdown --id 1S6Eg67vDSUSx6usqnAYgHCR2oEYeNvmI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0346c39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WRIsTi0zCs-",
    "outputId": "517d513d-2353-4672-fef5-2204f9302b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 23 11:36:44 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.13       Driver Version: 496.13       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P8    12W /  N/A |    125MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     18176      C   ...da3\\envs\\MuRIL\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e552267f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlFORVm4zCs_",
    "outputId": "78713c59-3e70-49e7-bd98-23a33458a6cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c75a642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPsBVUt4CPFK",
    "outputId": "953cf603-64ba-45e3-85be-bc007232150e"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "from collections import defaultdict, Counter\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from bert import bert_tokenization\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7975274",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GV9JIe0CO2b",
    "outputId": "27988521-db2e-4bcf-fbf0-4116cd5497e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Acer\n",
      " Volume Serial Number is 3818-7542\n",
      "\n",
      " Directory of C:\\Users\\phvpa\\OneDrive - Amrita Vishwa Vidyapeetham\\Amrita-Mtech-CEN\\ProjectWork\\MTech Thesis\\Denoise in Code mix data\\Experiments\\Malyalam\n",
      "\n",
      "23-10-2021  11:29    <DIR>          .\n",
      "23-10-2021  09:00    <DIR>          ..\n",
      "23-10-2021  09:19    <DIR>          .ipynb_checkpoints\n",
      "23-10-2021  11:33    <DIR>          1000 and 100 data\n",
      "23-10-2021  11:29            51,833 1000and100_MuRIL_SVM_DT_RF.ipynb\n",
      "20-10-2021  19:22            60,830 250and20MuRIL_SVM_DT_RF.ipynb\n",
      "21-10-2021  01:01    <DIR>          Colab_work\n",
      "23-10-2021  01:20            13,593 FastText.ipynb\n",
      "23-10-2021  09:49    <DIR>          Indice_BERT\n",
      "22-10-2021  04:02           187,035 Indice_BERT.ipynb\n",
      "23-05-2021  09:42           268,731 Mal_sentiment_full_dev.tsv\n",
      "16-06-2021  04:34           287,576 Mal_sentiment_full_test_withoutlabels.tsv\n",
      "23-05-2021  09:41         2,382,197 Mal_sentiment_full_train.tsv\n",
      "23-10-2021  09:17         6,268,128 Mal_train.npy\n",
      "23-10-2021  09:17             8,128 Mal_train_label.npy\n",
      "23-10-2021  09:17            84,128 Mal_val.npy\n",
      "23-10-2021  09:17               928 Mal_val_label.npy\n",
      "22-10-2021  16:01    <DIR>          MuRIL\n",
      "09-10-2021  13:22                 0 MURIL.py\n",
      "21-10-2021  22:37         5,539,584 WordEmbeddings.ipynb\n",
      "              13 File(s)     15,152,691 bytes\n",
      "               7 Dir(s)  331,324,616,704 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36949d52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6f18C1DCRRT",
    "outputId": "4982a2f2-ca5a-42a8-80b8-35ae41d71c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15888\n",
      "1766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1962"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df = pd.read_csv(\"Mal_sentiment_full_train.tsv\", header=None, sep='\\t')\n",
    "train_df = pd.read_csv(\"Mal_sentiment_full_train.tsv\", sep='\\t')\n",
    "print(len(train_df))\n",
    "\n",
    "#test_df = pd.read_csv(\"Mal_sentiment_full_dev.tsv\", header=None, sep='\\t')\n",
    "valid_df = pd.read_csv(\"Mal_sentiment_full_dev.tsv\", sep='\\t')\n",
    "print(len(valid_df))\n",
    "\n",
    "test_df = pd.read_csv(\"Mal_sentiment_full_test_withoutlabels.tsv\", sep='\\t')\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc8b4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny chechi fans evide like adichu power kani...</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angane july month ile ende aadyathe leave njan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ഏട്ടന്റെ പുതിയ പടത്തിനു വേണ്ടി കാത്തിരിക്കുന്ന...</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ഇനി ലാലേട്ടന്റെ വേട്ട തുടങ്ങാൻ പോകുന്നു..........</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trailer powli oru raksha illa . Pakshea padam ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15883</th>\n",
       "      <td>Minimum 10 thavana kandavar maathram like adi</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15884</th>\n",
       "      <td>Please cinema kaannaaan kothi aakunnu onnu rel...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15885</th>\n",
       "      <td>USA ok.. India No... Sadhacharam</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886</th>\n",
       "      <td>nama hero december 12 wait &amp; see  mamamaga mah...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887</th>\n",
       "      <td>Madhuraraja 1 hour 40 k likes  Lucifer 1 min 4...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15888 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text        category\n",
       "0      Sunny chechi fans evide like adichu power kani...   unknown_state\n",
       "1      Angane july month ile ende aadyathe leave njan...        Positive\n",
       "2      ഏട്ടന്റെ പുതിയ പടത്തിനു വേണ്ടി കാത്തിരിക്കുന്ന...   unknown_state\n",
       "3      ഇനി ലാലേട്ടന്റെ വേട്ട തുടങ്ങാൻ പോകുന്നു..........        Positive\n",
       "4      Trailer powli oru raksha illa . Pakshea padam ...        Positive\n",
       "...                                                  ...             ...\n",
       "15883      Minimum 10 thavana kandavar maathram like adi   unknown_state\n",
       "15884  Please cinema kaannaaan kothi aakunnu onnu rel...        Positive\n",
       "15885                   USA ok.. India No... Sadhacharam   unknown_state\n",
       "15886  nama hero december 12 wait & see  mamamaga mah...        Positive\n",
       "15887  Madhuraraja 1 hour 40 k likes  Lucifer 1 min 4...  Mixed_feelings\n",
       "\n",
       "[15888 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008088af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         unknown_state\n",
       "1              Positive\n",
       "2         unknown_state\n",
       "3              Positive\n",
       "4              Positive\n",
       "              ...      \n",
       "15883     unknown_state\n",
       "15884          Positive\n",
       "15885     unknown_state\n",
       "15886          Positive\n",
       "15887    Mixed_feelings\n",
       "Name: category, Length: 15888, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fea4be7",
   "metadata": {
    "id": "5M7bMSkdAhbS"
   },
   "outputs": [],
   "source": [
    "#removing all the emoji from the given data\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    temp1 = deEmojify(train_df['text'][i])\n",
    "    train_df['text'][i] = temp1\n",
    "\n",
    "for j in range(len(valid_df)):\n",
    "    temp2 = deEmojify(valid_df['text'][j])\n",
    "    valid_df['text'][j] = temp2\n",
    "\n",
    "for k in range(len(test_df)):\n",
    "    temp3 = deEmojify(test_df['text'][k])\n",
    "    test_df['text'][k]=temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ac983b",
   "metadata": {
    "id": "kvZOI__qZ7zd"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "  user_name = '@[A-Za-z0-9]+' # Pattern for matching the user names in the tweet\n",
    "  has_tag = '#[A-Za-z0-9]+' # Pattern for matching the hasgtags in the tweer\n",
    "  url = 'https?:\\/\\/[A-Za-z0-9\\.\\/\\-]+' # Pattern for matching the URLs in the tweet\n",
    "  #emoji_pattern = r'/[x{1F600}-x{1F64F}]/u'\n",
    "  \n",
    "  x = text.lower()  # Lower casing all the characters\n",
    "  x = re.sub(user_name, '', x) # Replace the username with an empty characrer\n",
    "  x = re.sub(has_tag,'',x) # Replace the hashtags with an empty characrer\n",
    "  x = re.sub(url, '', x) # Replace the URLs with an empty characrer\n",
    "  #x = re.sub(emoji_pattern, '', x)\n",
    "  x = x.translate(str.maketrans('', '', string.punctuation)) # Replace all the characters except alphabets and digits from the tweet\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbff7146",
   "metadata": {
    "id": "kXmiAchmcPq_"
   },
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].apply(lambda x: preprocess_data(x)) # Apply the clean_data() to all the entries in the dataframe\n",
    "valid_df['text'] = valid_df['text'].apply(lambda x: preprocess_data(x)) # Apply the clean_data() to all the entries in the dataframe\n",
    "test_df['text'] = test_df['text'].apply(lambda x: preprocess_data(x)) # Apply the clean_data() to all the entries in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56146dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oru panipalal manakunnu again mr jr \n",
      "ende ponno 68 vayasaya oraluda body thanneyano ith  namichu ponnikkaaaa\n",
      "fdfs trailer kandu ithu vareyum njanithu paranjittilla\n",
      "degraders step back   മമ്മൂക്ക\n",
      "ഈ പാട്ട് ഡിസ്‌ലൈക് ചെയ്തവരുടെ വീട്ടുകാരെ സമ്മതിക്കണം big salute\n",
      "ഇത് ഏത് ഭാഷ ശിവനെ ഏത് ജില്ല \n",
      "ഇതൊക്കെ മമ്മുക്ക പറഞ്ഞാൽ പൊളിക്കും   \n",
      "108 st pius x kuttikanam        uyir\n",
      "ente ponno heavy bgm ikka pinne parayanilla2 looks kidilosky  overall kidukkachi aahn mone\n",
      "song dislike adicha 90 perum phycho singles akum\n",
      "അഭ്യർത്ഥന  മാമാങ്കം പലകുറി കൊണ്ടാടും  എന്ന ഗാനം ടൈറ്റിൽ സോങ്ങ് ആയി ഉൾപ്പെടുത്താമോ  album vasantha geethangal singer k j yesudas\n"
     ]
    }
   ],
   "source": [
    "print(test_df['text'][279])\n",
    "print(test_df['text'][516])\n",
    "print(test_df['text'][546])\n",
    "print(test_df['text'][555])\n",
    "print(test_df['text'][559])\n",
    "print(test_df['text'][570])\n",
    "print(test_df['text'][825])\n",
    "print(test_df['text'][838])\n",
    "print(test_df['text'][860])\n",
    "print(test_df['text'][890])\n",
    "print(test_df['text'][1234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b67b994",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZaxBiC7ByJJH",
    "outputId": "309d6739-c912-43f9-d1f8-f5f88d0cef7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mammooka ninghal mass aa pwoli item'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341b295a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l445loMxdKoP",
    "outputId": "fa177767-8c3a-44b4-f2bc-65d6b542f619",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text        category\n",
      "0       sunny chechi fans evide like adichu power kaniku   unknown_state\n",
      "1      angane july month ile ende aadyathe leave njan...        Positive\n",
      "2      ഏട്ടന്റെ പുതിയ പടത്തിനു വേണ്ടി കാത്തിരിക്കുന്ന...   unknown_state\n",
      "3      ഇനി ലാലേട്ടന്റെ വേട്ട തുടങ്ങാൻ പോകുന്നു മുൻ കാ...        Positive\n",
      "4      trailer powli oru raksha illa  pakshea padam i...        Positive\n",
      "...                                                  ...             ...\n",
      "15883      minimum 10 thavana kandavar maathram like adi   unknown_state\n",
      "15884  please cinema kaannaaan kothi aakunnu onnu rel...        Positive\n",
      "15885                        usa ok india no sadhacharam   unknown_state\n",
      "15886  nama hero december 12 wait  see  mamamaga maha...        Positive\n",
      "15887  madhuraraja 1 hour 40 k likes  lucifer 1 min 4...  Mixed_feelings\n",
      "\n",
      "[15888 rows x 2 columns]\n",
      "\n",
      "                                                   text       category\n",
      "0                   mammooka ninghal mass aa pwoli item       Positive\n",
      "1         waiting for malayalam movie  for tamil paiyan  not-malayalam\n",
      "2           ദളപതി ഫാൻസിന്റെ വക ഒരു ഒന്നൊന്നര വിജയാശംസകൾ       Positive\n",
      "3            pwolichuuuu ഓണത്തിന് വന്നങ്ങു തകർത്തേക്ക്        Positive\n",
      "4      mammoookkaaaa polichadukkiii katta waiting nv 21       Positive\n",
      "...                                                 ...            ...\n",
      "1761            aa ചിരി uff എന്റെ പൊന്നോ ഇക്ക vere ലെവൽ       Positive\n",
      "1762       katta katta katta katta waitingcant wait man       Positive\n",
      "1763  arjun reddy bgm poole thonniyathu enniku mathr...  unknown_state\n",
      "1764             fahad ikka ithilum polikum en urappayi       Positive\n",
      "1765  njan veendum kanan vannu 100 pravashyam enkilu...       Positive\n",
      "\n",
      "[1766 rows x 2 columns]\n",
      "\n",
      "            id                                               text\n",
      "0        Mal_1    teaserinu kurach samayamkoodi mathram cant wait\n",
      "1        Mal_2                    അപ്പോൾ കഥയുടെ  റൂട്ട് മാറിയല്ലോ\n",
      "2        Mal_3      മൂത്തോൻ ട്രൈലെർ trending list വരാത്തത് എന്താ \n",
      "3        Mal_4  nowadays 944k views is considered as 1m views ...\n",
      "4        Mal_5  maasstrailer ennu paranja ithaanu makkalekatta...\n",
      "...        ...                                                ...\n",
      "1957  Mal_1958  expression വച്ചു നോക്കുമ്പോൾ മൂക്കുത്തി കട്ടത്...\n",
      "1958  Mal_1959                        എനിക്ക് ഒരു  100 like തരുമോ\n",
      "1959  Mal_1960  nannayi onnu poliyunna lakshnm undethrill main...\n",
      "1960  Mal_1961  athikam eduthu kayatti vekkendadirection kke k...\n",
      "1961  Mal_1962  ithupole mooonchiya oru padam jeevithathil kan...\n",
      "\n",
      "[1962 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)\n",
    "print()\n",
    "print(valid_df)\n",
    "print()\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f236a6",
   "metadata": {},
   "source": [
    "# Dividing train and valid separatly:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c35a2",
   "metadata": {},
   "source": [
    "### Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9aa1472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>tovinok pakaram unni mukundan mathiyarunnu</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>puthanpanam movie pole thonniyath enikk maathr...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>richie orma vanathu eniku mathram ano</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>friendship dayikk oru cake medichu kodukk  fresh</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>pulimurugan copy adi pole ind stund seen ellam</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>tesla code um കണ്ടിട്ട് ഇറങ്ങിയിട്ടുണ്ട് കുറേ</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>കമന്റ്‌ വായിക്കുന്ന ലാലേട്ടൻ ഫാൻസിന് ലൈക് അടിക...</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>eth sajiv pillai visuals ane  alle</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>katha manasilay tv il varambam kanam</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>pazhaya standbaker junction and aakasapatha id...</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1766 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        category\n",
       "974          tovinok pakaram unni mukundan mathiyarunnu  Mixed_feelings\n",
       "166   puthanpanam movie pole thonniyath enikk maathr...  Mixed_feelings\n",
       "536               richie orma vanathu eniku mathram ano  Mixed_feelings\n",
       "700    friendship dayikk oru cake medichu kodukk  fresh  Mixed_feelings\n",
       "1363     pulimurugan copy adi pole ind stund seen ellam  Mixed_feelings\n",
       "...                                                 ...             ...\n",
       "436       tesla code um കണ്ടിട്ട് ഇറങ്ങിയിട്ടുണ്ട് കുറേ   unknown_state\n",
       "1180  കമന്റ്‌ വായിക്കുന്ന ലാലേട്ടൻ ഫാൻസിന് ലൈക് അടിക...   unknown_state\n",
       "1182                 eth sajiv pillai visuals ane  alle   unknown_state\n",
       "1186               katha manasilay tv il varambam kanam   unknown_state\n",
       "882   pazhaya standbaker junction and aakasapatha id...   unknown_state\n",
       "\n",
       "[1766 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp2 = valid_df.sort_values('category')\n",
    "df_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6adcc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "count2 = 20\n",
    "val_Mixed_feelings = df_temp2[:count2]\n",
    "val_Negative = df_temp2[110:110+count2]\n",
    "val_Positive=df_temp2[350:350+count2]\n",
    "val_not_malayalam = df_temp2[1060:1060+count2]\n",
    "val_unknown_state = df_temp2[1190:1190+count2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "522f6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_frames = [val_Mixed_feelings, val_Negative, val_Positive, val_not_malayalam, val_unknown_state ]\n",
    "Val_results = pd.concat(Val_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7de2eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_val = Val_results.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a99c9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_val_list = Sub_val['text'].tolist()\n",
    "Sub_val_labels_list = Sub_val['category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab62a009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 2, 2, 0, 0, 2, 3, 0, 0, 4, 4, 0, 4, 4, 2, 0, 3, 2, 3, 0, 1,\n",
       "       1, 1, 4, 1, 4, 1, 2, 2, 4, 4, 1, 1, 3, 2, 0, 3, 3, 0, 2, 2, 3, 2,\n",
       "       2, 0, 1, 4, 0, 4, 3, 4, 1, 4, 0, 1, 1, 3, 3, 3, 3, 0, 1, 2, 0, 1,\n",
       "       0, 3, 0, 1, 4, 3, 2, 1, 0, 3, 3, 3, 2, 3, 0, 3, 3, 2, 4, 2, 1, 0,\n",
       "       4, 2, 2, 4, 4, 1, 1, 1, 2, 4, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "Y_val = le.fit_transform(Sub_val_labels_list)\n",
    "Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b3df6",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d9d271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = train_df.sort_values('category')\n",
    "count = 200\n",
    "Mixed_feelings = df_temp[:count]\n",
    "Negative = df_temp[950:950+count]\n",
    "Positive=df_temp[3040:3040+count]\n",
    "not_malayalam = df_temp[9460:9460+count]\n",
    "unknown_state = df_temp[10620:10620+count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ca430f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_frames = [Mixed_feelings, Negative, Positive, not_malayalam, unknown_state ]\n",
    "\n",
    "train_result = pd.concat(train_frames) #concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c9035ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_train = train_result.sample(frac = 1) #shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97e0daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_train_list = Sub_train['text'].tolist()\n",
    "Sub_labels_list = Sub_train['category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92566548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sub_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cabef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y_train = le.fit_transform(Sub_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a608939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfaac0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mal_val = np.array(Sub_val_list)\n",
    "np.save('Mal_val.npy',Mal_val)\n",
    "Mal_val_label = np.array(Y_val)\n",
    "np.save('Mal_val_label.npy',Mal_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f55c3d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "temp1 =np.load('Mal_val.npy')\n",
    "print(temp1.shape)\n",
    "temp1 =np.load('Mal_val_label.npy')\n",
    "print(temp1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea502a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mal_train = np.array(Sub_train_list)\n",
    "np.save('Mal_train.npy',Mal_train)\n",
    "Mal_train_label = np.array(Y_train)\n",
    "np.save('Mal_train_label.npy',Mal_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31a3f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "temp1 =np.load('Mal_train.npy')\n",
    "print(temp1.shape)\n",
    "temp1 =np.load('Mal_train_label.npy')\n",
    "print(temp1.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
